{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd506a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Imports & Setup\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71838381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Parameters\n",
    "\n",
    "DATA_DIR = \"nepali_dataset\"\n",
    "CHUNK_DURATION = 1.5  # seconds\n",
    "SAMPLE_RATE = 16000\n",
    "CHUNK_SIZE = int(SAMPLE_RATE * CHUNK_DURATION)\n",
    "TARGET_SHAPE = (128, 128)\n",
    "\n",
    "class_names = ['fluent', 'stutter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77227aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Audio to Log-Mel Conversion\n",
    "\n",
    "def extract_log_mel(audio, sr):\n",
    "    audio = audio / (np.max(np.abs(audio)) + 1e-6)\n",
    "    mel = librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=TARGET_SHAPE[0])\n",
    "    log_mel = librosa.power_to_db(mel)\n",
    "    h, w = log_mel.shape\n",
    "    pad_h = max(0, TARGET_SHAPE[0] - h)\n",
    "    pad_w = max(0, TARGET_SHAPE[1] - w)\n",
    "    log_mel = np.pad(log_mel, ((0, pad_h), (0, pad_w)), mode='constant')\n",
    "    return log_mel[:TARGET_SHAPE[0], :TARGET_SHAPE[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff33bfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Load and Process Dataset\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for label, class_name in enumerate(class_names):\n",
    "    folder = os.path.join(DATA_DIR, class_name)\n",
    "    if not os.path.isdir(folder):\n",
    "        continue\n",
    "\n",
    "    for file in os.listdir(folder):\n",
    "        if not file.endswith(\".wav\"):\n",
    "            continue\n",
    "\n",
    "        file_path = os.path.join(folder, file)\n",
    "        try:\n",
    "            audio, sr = librosa.load(file_path, sr=SAMPLE_RATE)\n",
    "            total_samples = len(audio)\n",
    "\n",
    "            for start in range(0, total_samples - CHUNK_SIZE + 1, CHUNK_SIZE):\n",
    "                chunk = audio[start:start + CHUNK_SIZE]\n",
    "                X.append(extract_log_mel(chunk, sr))\n",
    "                y.append(label)\n",
    "\n",
    "                # Augment 1: Add noise\n",
    "                noise = np.random.normal(0, 0.005, chunk.shape)\n",
    "                X.append(extract_log_mel(chunk + noise, sr))\n",
    "                y.append(label)\n",
    "\n",
    "                # Augment 2: Pitch shift\n",
    "                try:\n",
    "                    pitched = librosa.effects.pitch_shift(chunk, sr=sr, n_steps=2)\n",
    "                    X.append(extract_log_mel(pitched, sr))\n",
    "                    y.append(label)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                # Augment 3: Time stretch\n",
    "                try:\n",
    "                    stretched = librosa.effects.time_stretch(chunk, rate=1.1)\n",
    "                    if len(stretched) >= CHUNK_SIZE:\n",
    "                        stretched = stretched[:CHUNK_SIZE]\n",
    "                        X.append(extract_log_mel(stretched, sr))\n",
    "                        y.append(label)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] {file}: {e}\")\n",
    "\n",
    "# Finalize dataset\n",
    "X = np.stack(X).astype(np.float32)[..., np.newaxis]\n",
    "y = np.array(y)\n",
    "print(\"Total samples:\", len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1633dc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Train/Test Split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda6a2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) CNN Model\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(TARGET_SHAPE[0], TARGET_SHAPE[1], 1)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5925df9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------\n",
    "# 7) Train\n",
    "# ------------------------------------------\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=8, restore_best_weights=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(patience=4, factor=0.5),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\"best_stutter_model.h5\", save_best_only=True)\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=30,\n",
    "    batch_size=32,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b091252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) Save and Plot\n",
    "\n",
    "model.save(\"final_stutter_detection_flutter_cnn.h5\")\n",
    "\n",
    "# Plot training curves\n",
    "plt.plot(history.history['accuracy'], label='Train Acc')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(\"accuracy_plot.png\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(\"loss_plot.png\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Training complete. Model and plots saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a076a3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------\n",
    "# 11) Confusion Matrix & Classification Report\n",
    "# ------------------------------------------\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get predictions\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(int).flatten()\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.savefig(\"confusion_matrix.png\")\n",
    "plt.show()\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=class_names))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
